{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flickr8k_Data_Processing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IEuEQoobp3Zgame4xjn2nVEPSG7Yn614",
      "authorship_tag": "ABX9TyMnbzde3Yisd/KYqZc/ftXK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamunm/iamge_caption_generator/blob/main/notebooks/Flickr8k_Data_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJQMKimYAT89"
      },
      "source": [
        "Guided notebook for image captioning which is inspired by the machine learning mastery blog."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLUnOn5hBIfE"
      },
      "source": [
        "!pip install wandb -qqq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3nbsk9yC9Pp"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwqzcnQ4AzUa"
      },
      "source": [
        "# import python modules\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import string \n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "#import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvcrVzUIBHjY"
      },
      "source": [
        "# extract image features from a collection of images in a directory\n",
        "def extract_features(directory):\n",
        "    model = VGG16()\n",
        "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "    features = dict()\n",
        "    for name in tqdm(os.listdir(directory)):\n",
        "        filename = directory + '/' + name\n",
        "        image = load_img(filename, target_size=(224, 224))\n",
        "        image = img_to_array(image)\n",
        "        image = image.reshape((1, *image.shape))\n",
        "        image = preprocess_input(image)\n",
        "        feature = model.predict(image, verbose=0)\n",
        "        image_id = name.split('.')[0]\n",
        "        features[image_id] = feature\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hlWFm5eCnN-"
      },
      "source": [
        "# extract features from all images\n",
        "data_path = 'drive/MyDrive/image_captioning_data/Flickr8K'\n",
        "if not os.path.exists(os.path.join(data_path, 'features.pkl')):  \n",
        "    directory = os.path.join(data_path, 'Flicker8k_Dataset')\n",
        "    features = extract_features(directory)\n",
        "    print(f'Extracted Features: {len(features)}')\n",
        "    pickle.dump(features, open(os.path.join(data_path, \n",
        "                                            'features.pkl'), 'wb'))\n",
        "else:\n",
        "    features = pickle.load(open(os.path.join(data_path, \n",
        "                                             'features.pkl'), 'rb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtHiDr9vrNiP"
      },
      "source": [
        "# load doc into memory\n",
        "with open(os.path.join(data_path, \n",
        "                       'Flickr8k_text/Flickr8k.token.txt'), 'r') as f:\n",
        "    doc = f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ65RkdDDZ8R"
      },
      "source": [
        "# extract descriptions for images\n",
        "def load_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\t# process lines\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# remove filename from image id\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\t# convert description tokens back to string\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\t# create the list if needed\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = list()\n",
        "\t\t# store description\n",
        "\t\tmapping[image_id].append(image_desc)\n",
        "\treturn mapping\n",
        "\n",
        "def clean_descriptions(descriptions):\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor i in range(len(desc_list)):\n",
        "\t\t\tdesc = desc_list[i]\n",
        "\t\t\t# tokenize\n",
        "\t\t\tdesc = desc.split()\n",
        "\t\t\t# convert to lower case\n",
        "\t\t\tdesc = [word.lower() for word in desc]\n",
        "\t\t\t# remove punctuation from each token\n",
        "\t\t\tdesc = [w.translate(table) for w in desc]\n",
        "\t\t\t# remove hanging 's' and 'a'\n",
        "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
        "\t\t\t# remove tokens with numbers in them\n",
        "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
        "\t\t\t# store as string\n",
        "\t\t\tdesc_list[i] =  ' '.join(desc)\n",
        "\n",
        "# convert the loaded descriptions into a vocabulary of words\n",
        "def to_vocabulary(descriptions):\n",
        "\t# build a list of all description strings\n",
        "\tall_desc = set()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.update(d.split()) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "# save descriptions to file, one per line\n",
        "def save_descriptions(descriptions, filename):\n",
        "\tlines = list()\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\tlines.append(key + ' ' + desc)\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n",
        "\n",
        "# parse descriptions\n",
        "descriptions = load_descriptions(doc)\n",
        "print('Loaded: %d ' % len(descriptions))\n",
        "# clean descriptions\n",
        "clean_descriptions(descriptions)\n",
        "# summarize vocabulary\n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))\n",
        "# save to file\n",
        "save_descriptions(descriptions, os.path.join(data_path, \n",
        "                                             'descriptions.txt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycHho5jBEztl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}